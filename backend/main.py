from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, ValidationError
from typing import Optional, List, Dict, Any, AsyncGenerator
import os
import asyncio
import json
import random
from dotenv import load_dotenv

from modules.entity_extractor import EntityExtractor
from modules.text_rewriter import TextRewriter
from modules.metrics_calculator import MetricsCalculator
from modules.progress_manager import ProgressManager
from modules.ai_detector import AIDetector

# Load environment variables
load_dotenv()

app = FastAPI(
    title="Humanizador de Ensayos API",
    description="API para humanizar textos acad√©micos manteniendo naturalidad y preservando entidades",
    version="1.0.0"
)

# Configurar l√≠mite de tama√±o del body (10MB)
from fastapi import Request
from starlette.datastructures import UploadFile

@app.middleware("http")
async def increase_body_size(request: Request, call_next):
    request._body = await request.body()
    response = await call_next(request)
    return response

# Configure CORS - m√°s permisivo para desarrollo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Permitir cualquier origen en desarrollo
    allow_credentials=True,
    allow_methods=["*"],  # Permitir todos los m√©todos
    allow_headers=["*"],  # Permitir todos los headers
)

# Exception handler para errores de validaci√≥n
@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    print(f"[ERROR] Validation error: {exc.errors()}")
    return JSONResponse(
        status_code=400,
        content={"detail": str(exc.errors())}
    )

# Initialize modules
entity_extractor = EntityExtractor()
text_rewriter = TextRewriter()
metrics_calculator = MetricsCalculator()
progress_manager = ProgressManager()
ai_detector = AIDetector()

class HumanizeRequest(BaseModel):
    text: str
    budget: float = 0.2
    preserve_entities: bool = True
    respect_style: bool = False
    style_sample: Optional[str] = None
    level: Optional[str] = "standard"  # basic, standard, pro, ultimate
    voice: Optional[str] = "neutral"  # neutral | collective
    plan: Optional[str] = None  # free | basic | pro | ultra
    max_words: Optional[int] = None


class DiffItem(BaseModel):
    type: str  # "insert", "delete", "equal"
    token: str


class Metrics(BaseModel):
    change_ratio: float
    rare_words_ratio: float
    avg_sentence_len: float
    lix: float


class DetectRequest(BaseModel):
    text: str
    language: str = 'es'


class DetectResponse(BaseModel):
    is_ai: bool
    ai_probability: float
    human_score: float
    classification: str
    metrics: Dict[str, float]
    analysis: str


class HumanizeResponse(BaseModel):
    result: str
    diff: List[DiffItem]
    metrics: Metrics
    alerts: List[str]


@app.get("/")
async def root():
    return {"message": "Humanizador de Ensayos API v1.0.0"}

@app.get("/robots.txt")
async def robots_txt():
    return JSONResponse(content="User-agent: *\nDisallow:", media_type="text/plain")


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


@app.get("/test")
async def test_endpoint():
    return {
        "status": "ok", 
        "message": "Backend funcionando correctamente",
        "cors": "configured"
    }


@app.post("/api/detect", response_model=DetectResponse)
async def detect_ai(request: DetectRequest):
    """
    Detect if a text was generated by AI.
    Similar to GPT-Zero functionality.
    """
    try:
        result = ai_detector.detect(request.text, request.language)
        
        return DetectResponse(
            is_ai=result['is_ai'],
            ai_probability=result['ai_probability'],
            human_score=result['human_score'],
            classification=result['classification'],
            metrics=result['metrics'],
            analysis=result['analysis']
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/detect/start")
async def start_detect(request: DetectRequest):
    """Inicia una tarea de detecci√≥n con progreso SSE"""
    if not request.text or not request.text.strip():
        raise HTTPException(status_code=400, detail="El texto no puede estar vac√≠o")
    # Crear tarea
    task_id = progress_manager.create_task()
    # Lanzar proceso en background
    asyncio.create_task(process_detection(task_id, request))
    return {"task_id": task_id}


@app.get("/api/detect/progress/{task_id}")
async def detect_progress(task_id: str):
    """SSE para progreso de detecci√≥n"""
    async def event_generator():
        queue = progress_manager.add_listener(task_id)
        try:
            # Estado inicial
            status = progress_manager.get_task_status(task_id)
            if status:
                yield f"data: {json.dumps(status)}\n\n"
            while True:
                try:
                    update = await asyncio.wait_for(queue.get(), timeout=30.0)
                    if update.get("status") == "completed":
                        task_state = progress_manager.get_task_status(task_id) or {}
                        if task_state.get("result"):
                            update["result"] = task_state["result"]
                    yield f"data: {json.dumps(update)}\n\n"
                    if update.get("status") in ["completed", "error"]:
                        break
                except asyncio.TimeoutError:
                    yield f": heartbeat\n\n"
        finally:
            progress_manager.remove_listener(task_id, queue)
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.post("/api/detect/detailed")
async def detect_ai_detailed(request: DetectRequest):
    """
    Get a detailed AI detection report.
    """
    try:
        report = ai_detector.get_detailed_report(request.text, request.language)
        return {"report": report}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.options("/api/humanize")
async def humanize_options():
    print("[OPTIONS] Preflight request recibido")
    return {"message": "OK"}


@app.post("/api/humanize/start")
async def start_humanize(request: HumanizeRequest):
    """Start humanization task and return task ID for progress tracking"""
    
    # Validate request
    if not request.text or not request.text.strip():
        raise HTTPException(status_code=400, detail="El texto no puede estar vac√≠o")
    
    if request.budget < 0 or request.budget > 1:
        raise HTTPException(status_code=400, detail="El budget debe estar entre 0 y 1")
    
    # L√≠mite por plan (si viene)
    def _plan_max(plan: Optional[str]) -> int:
        m = { 'free': 600, 'basic': 800, 'pro': 1200, 'ultra': 1800 }
        return m.get((plan or '').lower(), 600)
    words_in = len((request.text or '').split())
    limit = request.max_words or _plan_max(request.plan)
    if words_in > limit:
        raise HTTPException(status_code=413, detail=f"Supera el m√°ximo por request ({limit} palabras)")

    # Create task
    task_id = progress_manager.create_task()
    
    # Start processing in background
    asyncio.create_task(process_humanization(task_id, request))
    
    return {"task_id": task_id}


@app.get("/api/humanize/progress/{task_id}")
async def get_progress(task_id: str):
    """Get SSE stream for task progress"""
    
    async def event_generator():
        """Generate SSE events"""
        queue = progress_manager.add_listener(task_id)
        
        try:
            # Send initial status
            status = progress_manager.get_task_status(task_id)
            if status:
                yield f"data: {json.dumps(status)}\n\n"
            
            # Stream updates
            while True:
                try:
                    # Wait for update with timeout
                    update = await asyncio.wait_for(queue.get(), timeout=30.0)
                    # Adjuntar resultado final si se complet√≥
                    if update.get("status") == "completed":
                        task_state = progress_manager.get_task_status(task_id) or {}
                        if task_state.get("result"):
                            update["result"] = task_state["result"]
                    yield f"data: {json.dumps(update)}\n\n"
                    
                    # Check if task is completed
                    if update.get("status") in ["completed", "error"]:
                        break
                        
                except asyncio.TimeoutError:
                    # Send heartbeat
                    yield f": heartbeat\n\n"
                    
        finally:
            progress_manager.remove_listener(task_id, queue)
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Disable Nginx buffering
        }
    )


async def process_humanization(task_id: str, request: HumanizeRequest):
    """Process humanization with progress updates"""
    
    try:
        is_ultimate = False
        
        # Fase 0-30%: an√°lisis y preparaci√≥n
        await progress_manager.update_progress(
            task_id, "processing", 1,
            "Iniciando proceso de humanizaci√≥n...",
            step=1, total_steps=10, phase="inicio"
        )
        await progress_manager.update_progress(
            task_id, "processing", 5,
            "Analizando estructura del texto (oraciones, p√°rrafos, longitud)...",
            step=2, total_steps=10, phase="an√°lisis"
        )
        await progress_manager.update_progress(
            task_id, "processing", 8,
            "Midiendo conectores y repetici√≥n (huellas t√≠picas de IA)...",
            step=3, total_steps=10, phase="an√°lisis"
        )
        await progress_manager.update_progress(
            task_id, "processing", 12,
            "Segmentando texto y preparando entidades a preservar...",
            step=4, total_steps=10, phase="preparaci√≥n"
        )
        
        # Extract and freeze entities
        frozen_entities = []
        processed_text = request.text
        runtime_alerts: List[str] = []
        
        if request.preserve_entities:
            await progress_manager.update_progress(
                task_id, "extracting", 16,
                "Extrayendo entidades acad√©micas (n√∫meros, fechas, citas)...",
                step=5, total_steps=10, phase="entidades"
            )
            frozen_entities, processed_text = entity_extractor.extract_and_freeze(request.text)
            
            await progress_manager.update_progress(
                task_id, "extracting", 18,
                f"{len(frozen_entities)} entidades preservadas",
                step=5, total_steps=10, phase="entidades"
            )
        
        # Preparaci√≥n de prompt y primer pase
        await progress_manager.update_progress(
            task_id, "processing", 20,
            "Construyendo prompt anti-detecci√≥n y estilo acad√©mico...",
            step=6, total_steps=10, phase="prompt"
        )
        await progress_manager.update_progress(
            task_id, "rewriting", 22,
            "Normalizando texto y preparando fragmentos virtuales...",
            step=7, total_steps=10, phase="reescritura"
        )
        await progress_manager.update_progress(
            task_id, "rewriting", 24,
            "Enviando a modelo (Primer pase)...",
            step=7, total_steps=10, phase="reescritura"
        )

        # Suavizado de progreso durante la llamada al modelo
        smoothing_stop_1 = asyncio.Event()
        smoothing_task_1: Optional[asyncio.Task] = None  # type: ignore

        async def smooth_progress(start: int, end: int, steps: int, label: str):
            # Incrementos suaves entre start‚Üíend en 'steps' con peque√±as demoras
            current = start
            for step in range(1, steps + 1):
                if smoothing_stop_1.is_set():
                    break
                frac = step / steps
                current = start + int((end - start) * frac)
                await progress_manager.update_progress(
                    task_id,
                    "rewriting",
                    current,
                    f"{label} {step}/{steps}",
                    step=7, total_steps=10, phase="reescritura"
                )
                # demoras variables 250‚Äì600 ms
                await asyncio.sleep(random.uniform(0.25, 0.6))

        # Callback de progreso por chunk (primer pase)
        async def on_rewrite_progress_pass1(event: str, i: int, total: int):
            nonlocal smoothing_task_1
            # En Standard simulamos 10 partes para que el usuario vea avance continuo
            virtual_total = 10 if not is_ultimate else total
            base_start = 30
            base_end = 50 if is_ultimate else 70
            if event == "chunk_start":
                smoothing_stop_1.clear()
                label = "Pase 1/3: reescribiendo parte" if is_ultimate else "Pase 1/1: reescribiendo parte"
                smoothing_task_1 = asyncio.create_task(
                    smooth_progress(base_start, base_end - 1, virtual_total, label)
                )
            else:
                # chunk_done: detener suavizado y fijar al final del rango
                smoothing_stop_1.set()
                try:
                    if smoothing_task_1:
                        await asyncio.wait_for(smoothing_task_1, timeout=0.1)
                except Exception:
                    pass
                await progress_manager.update_progress(
                    task_id,
                    "rewriting",
                    base_end,
                    ("Pase 1/3: partes completadas" if is_ultimate else "Pase 1/1: partes completadas"),
                    step=7, total_steps=10, phase="reescritura"
                )

        # Evaluaci√≥n previa con el detector para guiar al modelo
        pre_eval = ai_detector.detect(processed_text, 'es')

        # Contador de tokens en streaming
        produced_tokens = 0
        estimated_tokens = max(80, int(len(processed_text.split()) * 1.4))

        partial_buffer = ""
        async def on_tokens(prod: int, est: int, chunk: str = ""):
            nonlocal produced_tokens, estimated_tokens
            produced_tokens = prod
            estimated_tokens = max(est, estimated_tokens)
            prog = 24 + int( (70 - 24) * min(1.0, produced_tokens / max(1, estimated_tokens)) )
            # actualiza buffer parcial (truncar para no saturar)
            if chunk:
                partial = (partial_buffer + chunk)[-4000:]
            else:
                partial = None
            await progress_manager.update_progress(
                task_id, "rewriting", prog,
                f"Pase 1/1: generando ({produced_tokens}/{estimated_tokens} tokens)",
                step=7, total_steps=10, phase="streaming", partial=partial
            )

        rewrite_result = await text_rewriter.rewrite(
            text=processed_text,
            budget=request.budget,
            respect_style=request.respect_style,
            style_sample=request.style_sample,
            frozen_entities=frozen_entities,
            voice=request.voice,
            progress_callback=on_rewrite_progress_pass1,
            token_callback=on_tokens,
            detector_feedback=pre_eval.get('metrics', {})
        )
        # Robustez: asegurar que exista texto
        if not isinstance(rewrite_result, dict):
            rewrite_result = {"rewritten": processed_text, "notes": ["rewrite_result_invalido"]}
        if not isinstance(rewrite_result.get("rewritten", None), str) or not rewrite_result.get("rewritten", "").strip():
            rewrite_result["rewritten"] = processed_text
        
        # Second pass if Ultimate - pulido suave adicional
        if is_ultimate:
            await progress_manager.update_progress(
                task_id, "rewriting", 52,
                "Aplicando pase de pulido adicional (Nivel Ultimate)..."
            )
            
            # √önico pase extra de pulido (suave) para mejorar coherencia local
            second_budget = min(request.budget * 0.7, 0.4)
            second_pass_text = rewrite_result["rewritten"]
            
            # Callback de progreso por chunk (segundo pase)
            async def on_rewrite_progress_pass2(event: str, i: int, total: int):
                # Mapear a 52% - 72%
                base_start, base_end = 52, 72
                frac = (i - 1) / total if event == "chunk_start" else i / total
                percent = base_start + int((base_end - base_start) * frac)
                await progress_manager.update_progress(
                    task_id,
                    "rewriting",
                    max(min(percent, base_end), base_start),
                    f"Pase 2/2: procesando parte {i}/{total} ({'enviando' if event=='chunk_start' else 'recibida'})"
                )

            second_rewrite = await text_rewriter.rewrite(
                text=second_pass_text,
                budget=second_budget,
                respect_style=request.respect_style,
                style_sample=request.style_sample,
                frozen_entities=frozen_entities,
                progress_callback=on_rewrite_progress_pass2
            )
            
            # El resultado ya tiene los placeholders, no necesitamos restaurar aqu√≠
            rewrite_result["rewritten"] = second_rewrite["rewritten"]
            rewrite_result.setdefault("notes", []).append("Pulido final aplicado (variaci√≥n moderada, coherencia priorizada)")
        
        # Verify entities
        if request.preserve_entities:
            await progress_manager.update_progress(
                task_id, "verifying", 74,
                "Verificando preservaci√≥n de entidades (1/2)...",
                step=8, total_steps=10, phase="verificaci√≥n"
            )
            
            # Siempre restaurar las entidades antes de verificar
            rewrite_result["rewritten"] = entity_extractor.restore_entities(rewrite_result["rewritten"])
            
            await progress_manager.update_progress(
                task_id, "verifying", 78,
                "Verificando preservaci√≥n de entidades (2/2)...",
                step=8, total_steps=10, phase="verificaci√≥n"
            )
            
            # Then verify they were preserved (no interrumpir el flujo si falla)
            try:
                entity_extractor.verify_entities_preserved(
                    original_text=request.text,
                    rewritten_text=rewrite_result["rewritten"],
                    frozen_entities=frozen_entities
                )
            except ValueError as ve:
                runtime_alerts.append(f"‚ö†Ô∏è Entidades no preservadas completamente: {str(ve)}")
        
        # Calculate metrics
        await progress_manager.update_progress(
            task_id, "metrics", 82,
            "Calculando m√©tricas de calidad (cambio de tokens)...",
            step=9, total_steps=10, phase="m√©tricas"
        )
        await progress_manager.update_progress(
            task_id, "metrics", 86,
            "Calculando m√©tricas de calidad (LIX, longitud media)...",
            step=9, total_steps=10, phase="m√©tricas"
        )
        
        try:
            metrics = metrics_calculator.calculate(
                original_text=request.text,
                rewritten_text=rewrite_result["rewritten"]
            )
        except Exception as _:
            metrics = {
                "change_ratio": 0.0,
                "rare_words_ratio": 0.0,
                "avg_sentence_len": 0.0,
                "lix": 0.0
            }
        
        # Generate diff
        await progress_manager.update_progress(
            task_id, "finalizing", 90,
            "Generando comparaci√≥n de cambios (tokenizando)...",
            step=10, total_steps=10, phase="finalizaci√≥n"
        )
        await progress_manager.update_progress(
            task_id, "finalizing", 97,
            "Generando comparaci√≥n de cambios (render de diff)...",
            step=10, total_steps=10, phase="finalizaci√≥n"
        )
        
        try:
            diff = metrics_calculator.generate_diff(
                original_text=request.text,
                rewritten_text=rewrite_result["rewritten"]
            )
        except Exception:
            diff = []
        
        # Prepare alerts
        alerts = []
        if request.preserve_entities and frozen_entities:
            alerts.append(f"Se preservaron {len(frozen_entities)} entidades")
        
        if not text_rewriter.is_api_available():
            alerts.append("‚ö†Ô∏è Modo demo - texto sin modificar")
        
        alerts.extend(runtime_alerts)
        alerts.extend(rewrite_result.get("notes", []))
        
        # Store result in task
        result = {
            "result": rewrite_result["rewritten"],
            "diff": diff,
            "metrics": metrics,
            "alerts": alerts
        }
        
        progress_manager.tasks[task_id]["result"] = result
        
        # Complete task
        await progress_manager.complete_task(task_id, success=True)
        
    except Exception as e:
        # No romper: devolver al menos texto original con notas de error
        err = str(e)
        try:
            await progress_manager.update_progress(task_id, "error", 95, f"Fallo en post-proceso: {err}", step=10, total_steps=10, phase="finalizaci√≥n")
        except Exception:
            pass
        progress_manager.tasks[task_id]["result"] = {
            "result": request.text,
            "diff": [],
            "metrics": {"change_ratio": 0.0, "rare_words_ratio": 0.0, "avg_sentence_len": 0.0, "lix": 0.0},
            "alerts": ["‚ö†Ô∏è Proceso incompleto: se devolvi√≥ el texto original"]
        }
        await progress_manager.complete_task(task_id, success=True)


@app.get("/api/humanize/result/{task_id}")
async def get_result(task_id: str):
    """Get the final result of a completed task"""
    
    task = progress_manager.get_task_status(task_id)
    
    if not task:
        raise HTTPException(status_code=404, detail="Tarea no encontrada")
    
    if not task.get("completed"):
        raise HTTPException(status_code=425, detail="Tarea a√∫n en proceso")
    
    if not task.get("success"):
        raise HTTPException(status_code=500, detail=task.get("error", "Error desconocido"))
    
    result = task.get("result")
    if not result:
        raise HTTPException(status_code=500, detail="Resultado no disponible")
    
    return HumanizeResponse(
        result=result["result"],
        diff=result["diff"],
        metrics=Metrics(**result["metrics"]),
        alerts=result["alerts"]
    )


async def process_detection(task_id: str, request: DetectRequest):
    """Procesa la detecci√≥n con actualizaciones de progreso"""
    try:
        text = request.text
        lang = request.language or 'es'
        await progress_manager.update_progress(task_id, "detecting", 5, "Iniciando an√°lisis de IA...")

        # Paso 1: tokenizaci√≥n/segmentaci√≥n
        await progress_manager.update_progress(task_id, "detecting", 15, "Tokenizando y segmentando oraciones...")
        # (Informativo, el c√°lculo real viene luego)

        # Paso 2: patrones y conectores
        await progress_manager.update_progress(task_id, "detecting", 35, "Analizando conectores y patrones t√≠picos de IA...")
        pattern_score = ai_detector._calculate_pattern_score(text, lang)
        conn = ai_detector._connector_metrics(text)

        # Paso 3: m√©tricas principales
        await progress_manager.update_progress(task_id, "detecting", 55, "Calculando perplejidad, explosividad y diversidad l√©xica...")
        perplexity = ai_detector._calculate_perplexity(text, lang)
        burstiness = ai_detector._calculate_burstiness(text)
        sentence_variation = ai_detector._calculate_sentence_variation(text)
        vocabulary_diversity = ai_detector._calculate_vocabulary_diversity(text, lang)
        readability = ai_detector._calculate_readability(text)
        repetition_score = ai_detector._calculate_repetition_score(text)
        clause_var = ai_detector._clause_depth_variance(text)

        metrics = {
            'perplexity': perplexity,
            'burstiness': burstiness,
            'sentence_variation': sentence_variation,
            'vocabulary_diversity': vocabulary_diversity,
            'pattern_score': pattern_score,
            'readability': readability,
            'repetition_score': repetition_score,
            'connector_variety': conn['connector_variety'],
            'connector_overuse': 100 - conn['connector_overuse'],
            'clause_depth_variance': clause_var,
        }

        await progress_manager.update_progress(task_id, "detecting", 70, "Combinando m√©tricas en un √≠ndice global...")
        ai_prob = ai_detector._calculate_ai_probability(metrics)
        human_score = round(100.0 - ai_prob, 2)

        await progress_manager.update_progress(task_id, "detecting", 82, "Generando an√°lisis e interpretaci√≥n...")
        analysis = ai_detector._generate_analysis(metrics, ai_prob)
        classification = ai_detector._get_classification(human_score)

        # Paso 4: calibraci√≥n opcional con DeepSeek
        await progress_manager.update_progress(task_id, "detecting", 90, "Calibrando con modelo externo (opcional)...")
        try:
            calibrated = await ai_detector.calibrate_with_deepseek(text, ai_prob, metrics)  # type: ignore
        except Exception:
            calibrated = None
        if calibrated is not None:
            ai_prob = round(calibrated, 2)
            human_score = round(100.0 - ai_prob, 2)
            classification = ai_detector._get_classification(human_score)

        result = {
            'is_ai': ai_prob > 50.0,
            'ai_probability': ai_prob,
            'human_score': human_score,
            'classification': classification,
            'metrics': metrics,
            'analysis': analysis,
        }

        # Guardar y completar
        progress_manager.tasks[task_id]["result"] = result
        await progress_manager.complete_task(task_id, success=True)
    except Exception as e:
        error_msg = f"Error: {str(e)}"
        await progress_manager.complete_task(task_id, success=False, error=error_msg)


@app.post("/api/humanize", response_model=HumanizeResponse)
async def humanize_text(request: HumanizeRequest):
    # Detectar si es nivel Ultimate para doble procesamiento
    is_ultimate = False
    print(f"\n[DEBUG] Request recibido: text='{request.text[:50]}...', budget={request.budget}, level={request.level}")
    
    if not request.text or not request.text.strip():
        print("[ERROR] Texto vac√≠o")
        raise HTTPException(status_code=400, detail="El texto no puede estar vac√≠o")
    
    if request.budget < 0 or request.budget > 1:
        print(f"[ERROR] Budget inv√°lido: {request.budget}")
        raise HTTPException(status_code=400, detail="El budget debe estar entre 0 y 1")
    
    # Validar m√°ximo por plan si est√° disponible
    def _plan_max(plan: Optional[str]) -> int:
        m = { 'free': 600, 'basic': 800, 'pro': 1200, 'ultra': 1800 }
        return m.get((plan or '').lower(), 600)
    words_in = len((request.text or '').split())
    limit = request.max_words or _plan_max(request.plan)
    if words_in > limit:
        raise HTTPException(status_code=413, detail=f"Supera el m√°ximo por request ({limit} palabras)")

    try:
        print(f"\n[HUMANIZADOR] Nueva petici√≥n recibida - {len(request.text)} caracteres")
        print(f"[HUMANIZADOR] Configuraci√≥n: budget={request.budget}, level={request.level}, preserve_entities={request.preserve_entities}")
        
        # Extract and freeze entities if preserve_entities is True
        frozen_entities = []
        processed_text = request.text
        
        if request.preserve_entities:
            print("[HUMANIZADOR] Extrayendo y preservando entidades acad√©micas...")
            frozen_entities, processed_text = entity_extractor.extract_and_freeze(request.text)
            print(f"[HUMANIZADOR] {len(frozen_entities)} entidades preservadas")
        
        # First rewrite pass
        print("[HUMANIZADOR] Enviando texto a DeepSeek para humanizaci√≥n...")
        rewrite_result = await text_rewriter.rewrite(
            text=processed_text,
            budget=request.budget,
            respect_style=request.respect_style,
            style_sample=request.style_sample,
            frozen_entities=frozen_entities,
            voice=request.voice
        )
        print("[HUMANIZADOR] Primer pase de humanizaci√≥n completado")
        
        # Second and Third pass if Ultimate level
        if is_ultimate:
            print("[HUMANIZADOR] Nivel Ultimate detectado - Aplicando m√∫ltiples pases de humanizaci√≥n...")
            
            # Segundo pase con budget medio
            second_budget = min(request.budget * 0.8, 0.6)
            second_pass_text = rewrite_result["rewritten"]
            
            print("[HUMANIZADOR] Aplicando segundo pase (2/3)...")
            second_rewrite = await text_rewriter.rewrite(
                text=second_pass_text,
                budget=second_budget,
                respect_style=request.respect_style,
                style_sample=request.style_sample,
                frozen_entities=frozen_entities
            )
            
            # Tercer pase de pulido final
            print("[HUMANIZADOR] Aplicando tercer pase anti-detecci√≥n (3/3)...")
            third_budget = min(request.budget * 0.5, 0.4)
            third_pass_text = second_rewrite["rewritten"]
            
            third_rewrite = await text_rewriter.rewrite(
                text=third_pass_text,
                budget=third_budget,
                respect_style=request.respect_style,
                style_sample=request.style_sample,
                frozen_entities=frozen_entities
            )
            
            # El resultado ya tiene los placeholders, no necesitamos restaurar aqu√≠
            rewrite_result["rewritten"] = third_rewrite["rewritten"]
            rewrite_result.setdefault("notes", []).append("üî• Triple pase Ultimate aplicado (95%+ humano)")
            print("[HUMANIZADOR] Triple pase completado - Optimizado para 95%+ humanidad")
        
        # Restore entities before verification
        if request.preserve_entities:
            # First restore entities in the rewritten text
            rewrite_result["rewritten"] = entity_extractor.restore_entities(rewrite_result["rewritten"])
            
            # Then verify they were preserved
            entity_extractor.verify_entities_preserved(
                original_text=request.text,
                rewritten_text=rewrite_result["rewritten"],
                frozen_entities=frozen_entities
            )
        
        # Calculate metrics
        print("[HUMANIZADOR] Calculando m√©tricas de humanizaci√≥n...")
        metrics = metrics_calculator.calculate(
            original_text=request.text,
            rewritten_text=rewrite_result["rewritten"]
        )
        
        # Generate diff
        print("[HUMANIZADOR] Generando diferencias visuales...")
        diff = metrics_calculator.generate_diff(
            original_text=request.text,
            rewritten_text=rewrite_result["rewritten"]
        )
        print(f"[HUMANIZADOR] Proceso completado - Ratio de cambio: {metrics['change_ratio']:.2%}")
        
        # Generate alerts
        alerts = []
        if request.preserve_entities and frozen_entities:
            alerts.append(f"Se preservaron {len(frozen_entities)} entidades (cifras, fechas, citas)")
        
        if not text_rewriter.is_api_available():
            alerts.append("‚ö†Ô∏è Sin API key v√°lida - modo demo (texto sin modificar)")
        
        # Add rewriter notes to alerts
        alerts.extend(rewrite_result.get("notes", []))
        
        return HumanizeResponse(
            result=rewrite_result["rewritten"],
            diff=diff,
            metrics=Metrics(**metrics),
            alerts=alerts
        )
    
    except ValueError as e:
        # Entity preservation errors
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        # General processing errors
        error_msg = f"Error procesando el texto: {str(e)}"
        print(f"API Error: {error_msg}")  # Log for debugging
        raise HTTPException(status_code=500, detail=error_msg)


if __name__ == "__main__":
    import uvicorn
    host = os.getenv("HOST", "localhost")
    port = int(os.getenv("PORT", 8000))
    debug = os.getenv("DEBUG", "True").lower() == "true"
    
    uvicorn.run("main:app", host=host, port=port, reload=debug)
