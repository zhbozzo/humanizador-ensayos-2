from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, ValidationError
from typing import Optional, List, Dict, Any, AsyncGenerator
import os
import asyncio
import json
import random
from dotenv import load_dotenv

from modules.entity_extractor import EntityExtractor
from modules.text_rewriter import TextRewriter
from modules.metrics_calculator import MetricsCalculator
from modules.progress_manager import ProgressManager
from modules.ai_detector import AIDetector

# Load environment variables
load_dotenv()

app = FastAPI(
    title="Humanizador de Ensayos API",
    description="API para humanizar textos académicos manteniendo naturalidad y preservando entidades",
    version="1.0.0"
)

# Configurar límite de tamaño del body (10MB)
from fastapi import Request
from starlette.datastructures import UploadFile

@app.middleware("http")
async def increase_body_size(request: Request, call_next):
    request._body = await request.body()
    response = await call_next(request)
    return response

# Configure CORS - más permisivo para desarrollo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Permitir cualquier origen en desarrollo
    allow_credentials=True,
    allow_methods=["*"],  # Permitir todos los métodos
    allow_headers=["*"],  # Permitir todos los headers
)

# Exception handler para errores de validación
@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    print(f"[ERROR] Validation error: {exc.errors()}")
    return JSONResponse(
        status_code=400,
        content={"detail": str(exc.errors())}
    )

# Initialize modules
entity_extractor = EntityExtractor()
text_rewriter = TextRewriter()
metrics_calculator = MetricsCalculator()
progress_manager = ProgressManager()
ai_detector = AIDetector()

class HumanizeRequest(BaseModel):
    text: str
    budget: float = 0.2
    preserve_entities: bool = True
    respect_style: bool = False
    style_sample: Optional[str] = None
    level: Optional[str] = "standard"  # basic, standard, pro, ultimate
    voice: Optional[str] = "neutral"  # neutral | collective
    plan: Optional[str] = None  # free | basic | pro | ultra
    max_words: Optional[int] = None


class DiffItem(BaseModel):
    type: str  # "insert", "delete", "equal"
    token: str


class Metrics(BaseModel):
    change_ratio: float
    rare_words_ratio: float
    avg_sentence_len: float
    lix: float


class DetectRequest(BaseModel):
    text: str
    language: str = 'es'


class DetectResponse(BaseModel):
    is_ai: bool
    ai_probability: float
    human_score: float
    classification: str
    metrics: Dict[str, float]
    analysis: str


class HumanizeResponse(BaseModel):
    result: str
    diff: List[DiffItem]
    metrics: Metrics
    alerts: List[str]


@app.get("/")
async def root():
    return {"message": "Humanizador de Ensayos API v1.0.0"}

@app.get("/robots.txt")
async def robots_txt():
    return JSONResponse(content="User-agent: *\nDisallow:", media_type="text/plain")


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


@app.get("/test")
async def test_endpoint():
    return {
        "status": "ok", 
        "message": "Backend funcionando correctamente",
        "cors": "configured"
    }


@app.post("/api/detect", response_model=DetectResponse)
async def detect_ai(request: DetectRequest):
    """
    Detect if a text was generated by AI.
    Similar to GPT-Zero functionality.
    """
    try:
        result = ai_detector.detect(request.text, request.language)
        
        return DetectResponse(
            is_ai=result['is_ai'],
            ai_probability=result['ai_probability'],
            human_score=result['human_score'],
            classification=result['classification'],
            metrics=result['metrics'],
            analysis=result['analysis']
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/detect/start")
async def start_detect(request: DetectRequest):
    """Inicia una tarea de detección con progreso SSE"""
    if not request.text or not request.text.strip():
        raise HTTPException(status_code=400, detail="El texto no puede estar vacío")
    # Crear tarea
    task_id = progress_manager.create_task()
    # Lanzar proceso en background
    asyncio.create_task(process_detection(task_id, request))
    return {"task_id": task_id}


@app.get("/api/detect/progress/{task_id}")
async def detect_progress(task_id: str):
    """SSE para progreso de detección"""
    async def event_generator():
        queue = progress_manager.add_listener(task_id)
        try:
            # Estado inicial
            status = progress_manager.get_task_status(task_id)
            if status:
                yield f"data: {json.dumps(status)}\n\n"
            while True:
                try:
                    update = await asyncio.wait_for(queue.get(), timeout=30.0)
                    if update.get("status") == "completed":
                        task_state = progress_manager.get_task_status(task_id) or {}
                        if task_state.get("result"):
                            update["result"] = task_state["result"]
                    yield f"data: {json.dumps(update)}\n\n"
                    if update.get("status") in ["completed", "error"]:
                        break
                except asyncio.TimeoutError:
                    yield f": heartbeat\n\n"
        finally:
            progress_manager.remove_listener(task_id, queue)
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.post("/api/detect/detailed")
async def detect_ai_detailed(request: DetectRequest):
    """
    Get a detailed AI detection report.
    """
    try:
        report = ai_detector.get_detailed_report(request.text, request.language)
        return {"report": report}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.options("/api/humanize")
async def humanize_options():
    print("[OPTIONS] Preflight request recibido")
    return {"message": "OK"}


@app.post("/api/humanize/start")
async def start_humanize(request: HumanizeRequest):
    """Start humanization task and return task ID for progress tracking"""
    
    # Validate request
    if not request.text or not request.text.strip():
        raise HTTPException(status_code=400, detail="El texto no puede estar vacío")
    
    if request.budget < 0 or request.budget > 1:
        raise HTTPException(status_code=400, detail="El budget debe estar entre 0 y 1")
    
    # Límite por plan (si viene)
    def _plan_max(plan: Optional[str]) -> int:
        m = { 'free': 600, 'basic': 800, 'pro': 1200, 'ultra': 1800 }
        return m.get((plan or '').lower(), 600)
    words_in = len((request.text or '').split())
    limit = request.max_words or _plan_max(request.plan)
    if words_in > limit:
        raise HTTPException(status_code=413, detail=f"Supera el máximo por request ({limit} palabras)")

    # Create task
    task_id = progress_manager.create_task()
    
    # Start processing in background
    asyncio.create_task(process_humanization(task_id, request))
    
    return {"task_id": task_id}


@app.get("/api/humanize/progress/{task_id}")
async def get_progress(task_id: str):
    """Get SSE stream for task progress"""
    
    async def event_generator():
        """Generate SSE events"""
        queue = progress_manager.add_listener(task_id)
        
        try:
            # Send initial status
            status = progress_manager.get_task_status(task_id)
            if status:
                yield f"data: {json.dumps(status)}\n\n"
            
            # Stream updates
            while True:
                try:
                    # Wait for update with timeout
                    update = await asyncio.wait_for(queue.get(), timeout=30.0)
                    # Adjuntar resultado final si se completó
                    if update.get("status") == "completed":
                        task_state = progress_manager.get_task_status(task_id) or {}
                        if task_state.get("result"):
                            update["result"] = task_state["result"]
                    yield f"data: {json.dumps(update)}\n\n"
                    
                    # Check if task is completed
                    if update.get("status") in ["completed", "error"]:
                        break
                        
                except asyncio.TimeoutError:
                    # Send heartbeat
                    yield f": heartbeat\n\n"
                    
        finally:
            progress_manager.remove_listener(task_id, queue)
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Disable Nginx buffering
        }
    )


async def process_humanization(task_id: str, request: HumanizeRequest):
    """Process humanization with progress updates"""
    
    try:
        is_ultimate = False
        
        # Fase 0-30%: análisis y preparación
        await progress_manager.update_progress(
            task_id, "processing", 1,
            "Iniciando proceso de humanización...",
            step=1, total_steps=10, phase="inicio"
        )
        await progress_manager.update_progress(
            task_id, "processing", 5,
            "Analizando estructura del texto (oraciones, párrafos, longitud)...",
            step=2, total_steps=10, phase="análisis"
        )
        await progress_manager.update_progress(
            task_id, "processing", 8,
            "Midiendo conectores y repetición (huellas típicas de IA)...",
            step=3, total_steps=10, phase="análisis"
        )
        await progress_manager.update_progress(
            task_id, "processing", 12,
            "Segmentando texto y preparando entidades a preservar...",
            step=4, total_steps=10, phase="preparación"
        )
        
        # Extract and freeze entities
        frozen_entities = []
        processed_text = request.text
        runtime_alerts: List[str] = []
        
        if request.preserve_entities:
            await progress_manager.update_progress(
                task_id, "extracting", 16,
                "Extrayendo entidades académicas (números, fechas, citas)...",
                step=5, total_steps=10, phase="entidades"
            )
            frozen_entities, processed_text = entity_extractor.extract_and_freeze(request.text)
            
            await progress_manager.update_progress(
                task_id, "extracting", 18,
                f"{len(frozen_entities)} entidades preservadas",
                step=5, total_steps=10, phase="entidades"
            )
        
        # Preparación de prompt y primer pase
        await progress_manager.update_progress(
            task_id, "processing", 20,
            "Construyendo prompt anti-detección y estilo académico...",
            step=6, total_steps=10, phase="prompt"
        )
        await progress_manager.update_progress(
            task_id, "rewriting", 22,
            "Normalizando texto y preparando fragmentos virtuales...",
            step=7, total_steps=10, phase="reescritura"
        )
        await progress_manager.update_progress(
            task_id, "rewriting", 24,
            "Enviando a modelo (Primer pase)...",
            step=7, total_steps=10, phase="reescritura"
        )

        # Suavizado de progreso durante la llamada al modelo
        smoothing_stop_1 = asyncio.Event()
        smoothing_task_1: Optional[asyncio.Task] = None  # type: ignore

        async def smooth_progress(start: int, end: int, steps: int, label: str):
            # Incrementos suaves entre start→end en 'steps' con pequeñas demoras
            current = start
            for step in range(1, steps + 1):
                if smoothing_stop_1.is_set():
                    break
                frac = step / steps
                current = start + int((end - start) * frac)
                await progress_manager.update_progress(
                    task_id,
                    "rewriting",
                    current,
                    f"{label} {step}/{steps}",
                    step=7, total_steps=10, phase="reescritura"
                )
                # demoras variables 250–600 ms
                await asyncio.sleep(random.uniform(0.25, 0.6))

        # Callback de progreso por chunk (primer pase)
        async def on_rewrite_progress_pass1(event: str, i: int, total: int):
            nonlocal smoothing_task_1
            # En Standard simulamos 10 partes para que el usuario vea avance continuo
            virtual_total = 10 if not is_ultimate else total
            base_start = 30
            base_end = 50 if is_ultimate else 70
            if event == "chunk_start":
                smoothing_stop_1.clear()
                label = "Pase 1/3: reescribiendo parte" if is_ultimate else "Pase 1/1: reescribiendo parte"
                smoothing_task_1 = asyncio.create_task(
                    smooth_progress(base_start, base_end - 1, virtual_total, label)
                )
            else:
                # chunk_done: detener suavizado y fijar al final del rango
                smoothing_stop_1.set()
                try:
                    if smoothing_task_1:
                        await asyncio.wait_for(smoothing_task_1, timeout=0.1)
                except Exception:
                    pass
                await progress_manager.update_progress(
                    task_id,
                    "rewriting",
                    base_end,
                    ("Pase 1/3: partes completadas" if is_ultimate else "Pase 1/1: partes completadas"),
                    step=7, total_steps=10, phase="reescritura"
                )

        # Evaluación previa con el detector para guiar al modelo
        pre_eval = ai_detector.detect(processed_text, 'es')

        # Contador de tokens en streaming
        produced_tokens = 0
        estimated_tokens = max(80, int(len(processed_text.split()) * 1.4))

        partial_buffer = ""
        async def on_tokens(prod: int, est: int, chunk: str = ""):
            nonlocal produced_tokens, estimated_tokens
            produced_tokens = prod
            estimated_tokens = max(est, estimated_tokens)
            prog = 24 + int( (70 - 24) * min(1.0, produced_tokens / max(1, estimated_tokens)) )
            # actualiza buffer parcial (truncar para no saturar)
            if chunk:
                partial = (partial_buffer + chunk)[-4000:]
            else:
                partial = None
            await progress_manager.update_progress(
                task_id, "rewriting", prog,
                f"Pase 1/1: generando ({produced_tokens}/{estimated_tokens} tokens)",
                step=7, total_steps=10, phase="streaming", partial=partial
            )

        rewrite_result = await text_rewriter.rewrite(
            text=processed_text,
            budget=request.budget,
            respect_style=request.respect_style,
            style_sample=request.style_sample,
            frozen_entities=frozen_entities,
            voice=request.voice,
            progress_callback=on_rewrite_progress_pass1,
            token_callback=on_tokens,
            detector_feedback=pre_eval.get('metrics', {})
        )
        # Robustez: asegurar que exista texto
        if not isinstance(rewrite_result, dict):
            rewrite_result = {"rewritten": processed_text, "notes": ["rewrite_result_invalido"]}
        if not isinstance(rewrite_result.get("rewritten", None), str) or not rewrite_result.get("rewritten", "").strip():
            rewrite_result["rewritten"] = processed_text
        
        # Second pass if Ultimate - pulido suave adicional
        if is_ultimate:
            await progress_manager.update_progress(
                task_id, "rewriting", 52,
                "Aplicando pase de pulido adicional (Nivel Ultimate)..."
            )
            
            # Único pase extra de pulido (suave) para mejorar coherencia local
            second_budget = min(request.budget * 0.7, 0.4)
            second_pass_text = rewrite_result["rewritten"]
            
            # Callback de progreso por chunk (segundo pase)
            async def on_rewrite_progress_pass2(event: str, i: int, total: int):
                # Mapear a 52% - 72%
                base_start, base_end = 52, 72
                frac = (i - 1) / total if event == "chunk_start" else i / total
                percent = base_start + int((base_end - base_start) * frac)
                await progress_manager.update_progress(
                    task_id,
                    "rewriting",
                    max(min(percent, base_end), base_start),
                    f"Pase 2/2: procesando parte {i}/{total} ({'enviando' if event=='chunk_start' else 'recibida'})"
                )

            second_rewrite = await text_rewriter.rewrite(
                text=second_pass_text,
                budget=second_budget,
                respect_style=request.respect_style,
                style_sample=request.style_sample,
                frozen_entities=frozen_entities,
                progress_callback=on_rewrite_progress_pass2
            )
            
            # El resultado ya tiene los placeholders, no necesitamos restaurar aquí
            rewrite_result["rewritten"] = second_rewrite["rewritten"]
            rewrite_result.setdefault("notes", []).append("Pulido final aplicado (variación moderada, coherencia priorizada)")
        
        # Verify entities
        if request.preserve_entities:
            await progress_manager.update_progress(
                task_id, "verifying", 74,
                "Verificando preservación de entidades (1/2)...",
                step=8, total_steps=10, phase="verificación"
            )
            
            # Siempre restaurar las entidades antes de verificar
            rewrite_result["rewritten"] = entity_extractor.restore_entities(rewrite_result["rewritten"])
            
            await progress_manager.update_progress(
                task_id, "verifying", 78,
                "Verificando preservación de entidades (2/2)...",
                step=8, total_steps=10, phase="verificación"
            )
            
            # Then verify they were preserved (no interrumpir el flujo si falla)
            try:
                entity_extractor.verify_entities_preserved(
                    original_text=request.text,
                    rewritten_text=rewrite_result["rewritten"],
                    frozen_entities=frozen_entities
                )
            except ValueError as ve:
                runtime_alerts.append(f"⚠️ Entidades no preservadas completamente: {str(ve)}")
        
        # Calculate metrics
        await progress_manager.update_progress(
            task_id, "metrics", 82,
            "Calculando métricas de calidad (cambio de tokens)...",
            step=9, total_steps=10, phase="métricas"
        )
        await progress_manager.update_progress(
            task_id, "metrics", 86,
            "Calculando métricas de calidad (LIX, longitud media)...",
            step=9, total_steps=10, phase="métricas"
        )
        
        try:
            metrics = metrics_calculator.calculate(
                original_text=request.text,
                rewritten_text=rewrite_result["rewritten"]
            )
        except Exception as _:
            metrics = {
                "change_ratio": 0.0,
                "rare_words_ratio": 0.0,
                "avg_sentence_len": 0.0,
                "lix": 0.0
            }
        
        # Generate diff
        await progress_manager.update_progress(
            task_id, "finalizing", 90,
            "Generando comparación de cambios (tokenizando)...",
            step=10, total_steps=10, phase="finalización"
        )
        await progress_manager.update_progress(
            task_id, "finalizing", 97,
            "Generando comparación de cambios (render de diff)...",
            step=10, total_steps=10, phase="finalización"
        )
        
        try:
            diff = metrics_calculator.generate_diff(
                original_text=request.text,
                rewritten_text=rewrite_result["rewritten"]
            )
        except Exception:
            diff = []
        
        # Prepare alerts
        alerts = []
        if request.preserve_entities and frozen_entities:
            alerts.append(f"Se preservaron {len(frozen_entities)} entidades")
        
        if not text_rewriter.is_api_available():
            alerts.append("⚠️ Modo demo - texto sin modificar")
        
        alerts.extend(runtime_alerts)
        alerts.extend(rewrite_result.get("notes", []))
        
        # Store result in task
        result = {
            "result": rewrite_result["rewritten"],
            "diff": diff,
            "metrics": metrics,
            "alerts": alerts
        }
        
        progress_manager.tasks[task_id]["result"] = result
        
        # Complete task
        await progress_manager.complete_task(task_id, success=True)
        
    except Exception as e:
        # No romper: devolver al menos texto original con notas de error
        err = str(e)
        try:
            await progress_manager.update_progress(task_id, "error", 95, f"Fallo en post-proceso: {err}", step=10, total_steps=10, phase="finalización")
        except Exception:
            pass
        progress_manager.tasks[task_id]["result"] = {
            "result": request.text,
            "diff": [],
            "metrics": {"change_ratio": 0.0, "rare_words_ratio": 0.0, "avg_sentence_len": 0.0, "lix": 0.0},
            "alerts": ["⚠️ Proceso incompleto: se devolvió el texto original"]
        }
        await progress_manager.complete_task(task_id, success=True)


@app.get("/api/humanize/result/{task_id}")
async def get_result(task_id: str):
    """Get the final result of a completed task"""
    
    task = progress_manager.get_task_status(task_id)
    
    if not task:
        raise HTTPException(status_code=404, detail="Tarea no encontrada")
    
    if not task.get("completed"):
        raise HTTPException(status_code=425, detail="Tarea aún en proceso")
    
    if not task.get("success"):
        raise HTTPException(status_code=500, detail=task.get("error", "Error desconocido"))
    
    result = task.get("result")
    if not result:
        raise HTTPException(status_code=500, detail="Resultado no disponible")
    
    return HumanizeResponse(
        result=result["result"],
        diff=result["diff"],
        metrics=Metrics(**result["metrics"]),
        alerts=result["alerts"]
    )


async def process_detection(task_id: str, request: DetectRequest):
    """Procesa la detección con actualizaciones de progreso"""
    try:
        text = request.text
        lang = request.language or 'es'
        await progress_manager.update_progress(task_id, "detecting", 5, "Iniciando análisis de IA...")

        # Paso 1: tokenización/segmentación
        await progress_manager.update_progress(task_id, "detecting", 15, "Tokenizando y segmentando oraciones...")
        # (Informativo, el cálculo real viene luego)

        # Paso 2: patrones y conectores
        await progress_manager.update_progress(task_id, "detecting", 35, "Analizando conectores y patrones típicos de IA...")
        pattern_score = ai_detector._calculate_pattern_score(text, lang)
        conn = ai_detector._connector_metrics(text)

        # Paso 3: métricas principales
        await progress_manager.update_progress(task_id, "detecting", 55, "Calculando perplejidad, explosividad y diversidad léxica...")
        perplexity = ai_detector._calculate_perplexity(text, lang)
        burstiness = ai_detector._calculate_burstiness(text)
        sentence_variation = ai_detector._calculate_sentence_variation(text)
        vocabulary_diversity = ai_detector._calculate_vocabulary_diversity(text, lang)
        readability = ai_detector._calculate_readability(text)
        repetition_score = ai_detector._calculate_repetition_score(text)
        clause_var = ai_detector._clause_depth_variance(text)

        metrics = {
            'perplexity': perplexity,
            'burstiness': burstiness,
            'sentence_variation': sentence_variation,
            'vocabulary_diversity': vocabulary_diversity,
            'pattern_score': pattern_score,
            'readability': readability,
            'repetition_score': repetition_score,
            'connector_variety': conn['connector_variety'],
            'connector_overuse': 100 - conn['connector_overuse'],
            'clause_depth_variance': clause_var,
        }

        await progress_manager.update_progress(task_id, "detecting", 70, "Combinando métricas en un índice global...")
        ai_prob = ai_detector._calculate_ai_probability(metrics)
        human_score = round(100.0 - ai_prob, 2)

        await progress_manager.update_progress(task_id, "detecting", 82, "Generando análisis e interpretación...")
        analysis = ai_detector._generate_analysis(metrics, ai_prob)
        classification = ai_detector._get_classification(human_score)

        # Paso 4: calibración opcional con DeepSeek
        await progress_manager.update_progress(task_id, "detecting", 90, "Calibrando con modelo externo (opcional)...")
        try:
            calibrated = await ai_detector.calibrate_with_deepseek(text, ai_prob, metrics)  # type: ignore
        except Exception:
            calibrated = None
        if calibrated is not None:
            ai_prob = round(calibrated, 2)
            human_score = round(100.0 - ai_prob, 2)
            classification = ai_detector._get_classification(human_score)

        result = {
            'is_ai': ai_prob > 50.0,
            'ai_probability': ai_prob,
            'human_score': human_score,
            'classification': classification,
            'metrics': metrics,
            'analysis': analysis,
        }

        # Guardar y completar
        progress_manager.tasks[task_id]["result"] = result
        await progress_manager.complete_task(task_id, success=True)
    except Exception as e:
        error_msg = f"Error: {str(e)}"
        await progress_manager.complete_task(task_id, success=False, error=error_msg)


@app.post("/api/humanize", response_model=HumanizeResponse)
async def humanize_text(request: HumanizeRequest):
    # Detectar si es nivel Ultimate para doble procesamiento
    is_ultimate = False
    print(f"\n[DEBUG] Request recibido: text='{request.text[:50]}...', budget={request.budget}, level={request.level}")
    
    if not request.text or not request.text.strip():
        print("[ERROR] Texto vacío")
        raise HTTPException(status_code=400, detail="El texto no puede estar vacío")
    
    if request.budget < 0 or request.budget > 1:
        print(f"[ERROR] Budget inválido: {request.budget}")
        raise HTTPException(status_code=400, detail="El budget debe estar entre 0 y 1")
    
    # Validar máximo por plan si está disponible
    def _plan_max(plan: Optional[str]) -> int:
        m = { 'free': 600, 'basic': 800, 'pro': 1200, 'ultra': 1800 }
        return m.get((plan or '').lower(), 600)
    words_in = len((request.text or '').split())
    limit = request.max_words or _plan_max(request.plan)
    if words_in > limit:
        raise HTTPException(status_code=413, detail=f"Supera el máximo por request ({limit} palabras)")

    try:
        print(f"\n[HUMANIZADOR] Nueva petición recibida - {len(request.text)} caracteres")
        print(f"[HUMANIZADOR] Configuración: budget={request.budget}, level={request.level}, preserve_entities={request.preserve_entities}")
        
        # Extract and freeze entities if preserve_entities is True
        frozen_entities = []
        processed_text = request.text
        
        if request.preserve_entities:
            print("[HUMANIZADOR] Extrayendo y preservando entidades académicas...")
            frozen_entities, processed_text = entity_extractor.extract_and_freeze(request.text)
            print(f"[HUMANIZADOR] {len(frozen_entities)} entidades preservadas")
        
        # First rewrite pass
        print("[HUMANIZADOR] Enviando texto a DeepSeek para humanización...")
        rewrite_result = await text_rewriter.rewrite(
            text=processed_text,
            budget=request.budget,
            respect_style=request.respect_style,
            style_sample=request.style_sample,
            frozen_entities=frozen_entities,
            voice=request.voice
        )
        print("[HUMANIZADOR] Primer pase de humanización completado")
        
        # Second and Third pass if Ultimate level
        if is_ultimate:
            print("[HUMANIZADOR] Nivel Ultimate detectado - Aplicando múltiples pases de humanización...")
            
            # Segundo pase con budget medio
            second_budget = min(request.budget * 0.8, 0.6)
            second_pass_text = rewrite_result["rewritten"]
            
            print("[HUMANIZADOR] Aplicando segundo pase (2/3)...")
            second_rewrite = await text_rewriter.rewrite(
                text=second_pass_text,
                budget=second_budget,
                respect_style=request.respect_style,
                style_sample=request.style_sample,
                frozen_entities=frozen_entities
            )
            
            # Tercer pase de pulido final
            print("[HUMANIZADOR] Aplicando tercer pase anti-detección (3/3)...")
            third_budget = min(request.budget * 0.5, 0.4)
            third_pass_text = second_rewrite["rewritten"]
            
            third_rewrite = await text_rewriter.rewrite(
                text=third_pass_text,
                budget=third_budget,
                respect_style=request.respect_style,
                style_sample=request.style_sample,
                frozen_entities=frozen_entities
            )
            
            # El resultado ya tiene los placeholders, no necesitamos restaurar aquí
            rewrite_result["rewritten"] = third_rewrite["rewritten"]
            rewrite_result.setdefault("notes", []).append("🔥 Triple pase Ultimate aplicado (95%+ humano)")
            print("[HUMANIZADOR] Triple pase completado - Optimizado para 95%+ humanidad")
        
        # Restore entities before verification
        if request.preserve_entities:
            # First restore entities in the rewritten text
            rewrite_result["rewritten"] = entity_extractor.restore_entities(rewrite_result["rewritten"])
            
            # Then verify they were preserved
            entity_extractor.verify_entities_preserved(
                original_text=request.text,
                rewritten_text=rewrite_result["rewritten"],
                frozen_entities=frozen_entities
            )
        
        # Calculate metrics
        print("[HUMANIZADOR] Calculando métricas de humanización...")
        metrics = metrics_calculator.calculate(
            original_text=request.text,
            rewritten_text=rewrite_result["rewritten"]
        )
        
        # Generate diff
        print("[HUMANIZADOR] Generando diferencias visuales...")
        diff = metrics_calculator.generate_diff(
            original_text=request.text,
            rewritten_text=rewrite_result["rewritten"]
        )
        print(f"[HUMANIZADOR] Proceso completado - Ratio de cambio: {metrics['change_ratio']:.2%}")
        
        # Generate alerts
        alerts = []
        if request.preserve_entities and frozen_entities:
            alerts.append(f"Se preservaron {len(frozen_entities)} entidades (cifras, fechas, citas)")
        
        if not text_rewriter.is_api_available():
            alerts.append("⚠️ Sin API key válida - modo demo (texto sin modificar)")
        
        # Add rewriter notes to alerts
        alerts.extend(rewrite_result.get("notes", []))
        
        return HumanizeResponse(
            result=rewrite_result["rewritten"],
            diff=diff,
            metrics=Metrics(**metrics),
            alerts=alerts
        )
    
    except ValueError as e:
        # Entity preservation errors
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        # General processing errors
        error_msg = f"Error procesando el texto: {str(e)}"
        print(f"API Error: {error_msg}")  # Log for debugging
        raise HTTPException(status_code=500, detail=error_msg)


if __name__ == "__main__":
    import uvicorn
    host = os.getenv("HOST", "localhost")
    port = int(os.getenv("PORT", 8000))
    debug = os.getenv("DEBUG", "True").lower() == "true"
    
    uvicorn.run("main:app", host=host, port=port, reload=debug)
